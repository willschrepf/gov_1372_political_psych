---
title: 'Data Exploration: Contextual Influences'
author: "Your name here"
date: "November 11, 2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
  word_document: default
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(estimatr)
library(haven)
library(stargazer)
library(readxl) # you might need to install the readxl package before loading it
library(plot.matrix) # you might need to install the plot.matrix package before loading it
library(sjlabelled) # you might need to install the sjlabelled package before loading it
library(effsize)
library(psych)
select <- dplyr::select
```


In this Data Exploration assignment we will again be exploring the Nationscape dataset (Tausanovitch and Vavreck 2020), which was used in Reny and Newman's (2021) study of the effecs of the protests after George Floyd's killing.

Unlike previous assignments, however, you will be asked to take a bigger role in defining the research question and identifying the specific data that you would need to use. *This is practice for operationalizing questions of the type you will do for your research project.* 

Throughout the assignment, we will provide a running example of how you might approach the tasks. For you own work, please do not use either this example or the Geroge Floyd protests.

**Note: Because this assignment is a bit different, you are require to do all of the questions (although non-data science students can skip question 7). This is to ensure that you have enough material for you blog post.**

If you have a question about any part of this assignment, please ask! Note that the actionable part of each question is **bolded**.

# Developing a Research Question about Contextual Influences

**Data Details:**

* File Name: \texttt{vars\_data.xlsx}

* Source: This file shows what variables are covered in each wave of the Nationscape Data Set (Tausanovitch and Vavreck 2020). We will be using data from the survey itself in other parts of the exercise, but which specific files and variables will be up to you! Therefore, we don't present them in depth here.

Variable Name         | Variable Description
--------------------- | --------------------------------------
\texttt{Date}         | The date of the wave of the Nationscape survey
\texttt{response\_id}  | This and all other variables are the names of variables in the Nationscape data; the cells are 1 if that variable was included in that week's survey and 0 otherwise


```{r}
#Load the data summarizing variable availability
NationscapeVars_1 <- read_xlsx('vars_data.xlsx',sheet = 1) #we're using the read_xlsx function from the readxl package, which lets you specify which sheet to upload if you are using Excel data with multiple sheets
NationscapeVars_2 <- read_xlsx('vars_data.xlsx',sheet = 2)
```

Now let's get the data from two sheets into one data set.

```{r}
NationscapeVars <- full_join(NationscapeVars_1,NationscapeVars_2) %>% # the full_join function keeps all rows in both objects and all columns
  replace(is.na(.),0) # since we know that the NAs generated in the last command weren't asked in the weeks that show up as NA, we can replace NAs with 0s
```



## Question 1

Contextual influences are all about the fleeting events that shift our attitudes and behavior. These can be something we personally experience, like encountering people on the street (Sands 2017) or voting at a school (Berger et al. 2008). But they can also be events we are exposed to by press coverage like Supreme Court decision (Tankard and Paluck 2017) or even emotions evoked by press coverage (as was experimentally modeled by Zeitzoff 2014). For this exercise we will think about events that people in a given state or across the country would plausibly have been exposed to via news coverage. **Think about events that happened between July 2019 and July 2020. Maybe this is something that made national news or maybe it was something that received a lot of coverage in your home state or region. Write down an example or two that you might be interested in considering. Use [Google Trends](https://trends.google.com/trends/?geo=US) to confirm that there was a spike in interest, as demonstrated by an increase in Google searches, in your event and include a screenshot or a hyperlink to your results.** Try entering a relevant search term and then using a "Custom time range" (one of the drop down options instead of the default ""Past 12 months") to make your visualization.

## My Question

I'm going to look at the first impeachment of Pres. Donald Trump; [Google Trends](https://trends.google.com/trends/explore?date=2019-07-01%202020-07-31&geo=US&q=impeachment) confirms a big spike around December 18, when the House voted to impeach on two articles.


## Question 2

Think about some outcomes of interest to you that might have been affected by the contextual influence of the event that you chose. Look in the Nationscape data for variables that fit your outcomes or are reasonable proxies for those outcomes. The variable names in the data you have loaded are pretty informative, but use the full data folder you downloaded earlier to look in the codebooks for more complete descriptions of the variables and how they are measured. There is a codebook in each week's folder; you can look at any week's codebook to get a sense of the variables that are common across the survey waves. **Make sure that your variables are present in the data for the time period in which you want to look for contextual effects. Present these results in a plot.**

```{r q2}
NationscapeVars %>%
  select(Date, pres_approval, consider_trump, pid7_legacy, ideo5, muslimban, age) %>%
  mutate(date = as.character(Date)) %>%
  filter(date == "2019-12-05" | date == "2019-12-12" | date == "2019-12-19" | date == "2019-12-26" | date == "2020-01-02")

heat_data <- NationscapeVars %>% mutate(across(.cols = everything(), as.logical)) %>% select(c(pres_approval, consider_trump, pid7_legacy, ideo5, muslimban, age))

plot(t(as.matrix(heat_data)), col = c('red','green'), las = 2)

```


All data are present!

## Question 3

**Based on what you have thought about and the data you have found, clearly state a specific research question and a hypothesis. Which channel (or channels) through which situational factors can affect political behavior does your hypothesis implicate? (In class, we talked about rational choice, priming, and emotional channels.)** The research question should not be obvious ahead of time (although you should have a theoretical expectation or competing hypotheses); it should be be descriptive, correlational, or causal in nature; and it should be answerable with the data you have available. Make sure your research question is specific; don't confuse the research question with a broader, motivating question that might be used to get people interested in your topic.

My research question is "Did the first impeachment of Donald Trump cause changes in people's political attitudes, policy positions, electoral intentions, or ideology? And were these effects different for those who were old enough to witness Bill Clinton's impeachment? This is an example of how situational context could influence political behavior through priming.


## Question 4

In academic and professional settings, peer feedback, especially early in a project, can force you to clarify your thinking and be an important source of ideas. It's also important to be able to give a quick 'elevator pitch' for your project (so named because it can be delivered in no more time than an elevator ride). We've randomly assigned you into groups to share your ideas so far and get your peers' input about sources you should read, different ways to approach your analysis, or questions about your hypotheses. **Get together in your groups, have everyone give their project's 'elevator pitch,' and gather feedback from your peers. Write at least one thing you took away from this session.** The next couple of questions will ask you to try to use the data to answer your research question and test your hypotheses, so be sure to brainstorm good ways to approach those tasks.

Someone had the idea to include "policy positions" as well, so I added that to my research question.


## Question 5

No research project exists in a vacuum. As you get ready for your final projects, we want you to practice finding, summarizing, and citing related literature. **Identify at least two academic articles that might provide some background for your research question. List the complete source citations and include links to the articles you found.** Google Scholar (https://scholar.google.com/) or Hollis (https://hollis.harvard.edu/) are good places to look for these.

Jacobson, Gary C. "Donald Trump and the parties: Impeachment, pandemic, protest, and electoral politics in 2020." Presidential Studies Quarterly 50.4 (2020): 762-795. [Link](https://onlinelibrary.wiley.com/doi/epdf/10.1111/psq.12682)

Lee, Changjun, Jieun Shin, and Ahreum Hong. "Does social media use really make people politically polarized? Direct and indirect effects of social media use on political polarization in South Korea." Telematics and Informatics 35.1 (2018): 245-254. [Link](https://www.sciencedirect.com/science/article/abs/pii/S0736585317305208)


## Question 6

**Read in the data from the weeks surrounding your event of interest and test your hypothesis. This can be something straightforward like a difference-in-means or you can plot a visualization of the data. Just take one of the approaches we have used in class before to get an initial sense for if the data provide evidence of the contextual effects you theorized.** Note that you might have to do a fair bit of data cleaning in order to do this. Pay particular attention to how missing data are coded.


### Example
First we will need to load and compile the data for the several weeks surrounding the mass shootings we are investigating.
```{r}
# load the weekly survey files

Jul18 <- read_dta('Nationscape-DataRelease_WeeklyMaterials_DTA/phase_1_v20200814/ns20191205/ns20191205.dta') %>%
  remove_all_labels()
Jul25 <- read_dta('Nationscape-dataRelease_WeeklyMaterials_DTA/phase_1_v20200814/ns20191212/ns20191212.dta')%>%
  remove_all_labels()
Aug01 <- read_dta('Nationscape-dataRelease_WeeklyMaterials_DTA/phase_1_v20200814/ns20191219/ns20191219.dta') %>%
  remove_all_labels()
Aug08 <- read_dta('Nationscape-dataRelease_WeeklyMaterials_DTA/phase_1_v20200814/ns20191226/ns20191226.dta')%>%
  remove_all_labels()
Aug15 <- read_dta('Nationscape-DataRelease_WeeklyMaterials_DTA/phase_2_v20200814/ns20200102/ns20200102.dta')%>%
  remove_all_labels()


# join them all together
full_data <- full_join(Jul18,Jul25) %>% 
  full_join(., Aug01) %>%
  full_join(., Aug08) %>%
  full_join(., Aug15)

# recode NAs
full_data <- full_data %>%
  mutate(across(.cols = everything(), ~na_if(., 999))) %>%
  mutate(across(.cols = everything(), ~na_if(., 888)))
```

```{r}
# create an indicator variable for surveys administered after impeachment
full_data <- full_data %>%
  mutate(treated = if_else(start_date > as.Date('2019-12-18'), TRUE, FALSE)) %>% 
  mutate(witnessed_bc_imp = if_else(age > 39, TRUE, FALSE)) %>%
  select(start_date, pres_approval, consider_trump, pid7_legacy, ideo5, muslimban, age, treated, witnessed_bc_imp)
```

As a first cut, we can try a difference in means. Don't forget to check the effect size.
```{r}
difference_in_means(pres_approval ~ treated, data = full_data %>% filter(as.Date('2019-12-05') < start_date) %>% filter(start_date < as.Date('2020-01-02')))
difference_in_means(consider_trump ~ treated, data = full_data %>% filter(as.Date('2019-12-05') < start_date) %>% filter(start_date < as.Date('2020-01-02')))
difference_in_means(pid7_legacy ~ treated, data = full_data %>% filter(as.Date('2019-12-05') < start_date) %>% filter(start_date < as.Date('2020-01-02')))
difference_in_means(ideo5 ~ treated, data = full_data %>% filter(as.Date('2019-12-05') < start_date) %>% filter(start_date < as.Date('2020-01-02')))
difference_in_means(muslimban ~ treated, data = full_data %>% filter(as.Date('2019-12-05') < start_date) %>% filter(start_date < as.Date('2020-01-02')))
difference_in_means(witnessed_bc_imp ~ treated, data = full_data %>% filter(as.Date('2019-12-05') < start_date) %>% filter(start_date < as.Date('2020-01-02')))

```

In order of greatest to least effect on the treatment: party preference, ideology, presidential approval, view on the muslim ban, witnessed Bill Clinton's impeachment, and consideration of Trump for 2020.

```{r graphing}
pres_approval_graph <- full_data %>%
  mutate(date = as.Date(start_date)) %>%
  group_by(date) %>%
  summarize(pres_approval = mean(pres_approval, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = pres_approval)) +
  geom_line() +
  geom_vline(xintercept = as.Date("2019-12-18"), color = "red") +
  labs(title = "Presidential Dispproval Before and After 12-18 Impeachment Vote", subtitle = "Higher Scores Mean Less Approval") +
  annotate("text", x  = as.Date("2019-12-30"), y=2.55, label = paste("diff. in means before/after: ", (difference_in_means(pres_approval ~ treated, data = full_data %>% filter(as.Date('2019-12-05') < start_date) %>% filter(start_date < as.Date('2020-01-02')))$coefficient[[1]])))

consider_trump_graph <- full_data %>%
  mutate(date = as.Date(start_date)) %>%
  group_by(date) %>%
  summarize(consider_trump = mean(consider_trump, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = consider_trump)) +
  geom_line() +
  geom_vline(xintercept = as.Date("2019-12-18"), color = "red") +
  labs(title = "Consideration of Trump for 2020 Election Before and After 12-18 Impeachment Vote", subtitle = "Higher Scores Mean Less Consideration") +
  annotate("text", x  = as.Date("2019-12-30"), y=1.53, label = paste("diff. in means before/after: ", (difference_in_means(consider_trump ~ treated, data = full_data %>% filter(as.Date('2019-12-05') < start_date) %>% filter(start_date < as.Date('2020-01-02')))$coefficient[[1]])))

pid7_legacy_graph <- full_data %>%
  mutate(date = as.Date(start_date)) %>%
  group_by(date) %>%
  summarize(pid7_legacy = mean(pid7_legacy, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = pid7_legacy)) +
  geom_line() +
  geom_vline(xintercept = as.Date("2019-12-18"), color = "red") +
  labs(title = "Party Identification Before and After 12-18 Impeachment Vote", subtitle = "1 = Strong D, 7 = Strong R")  +
  annotate("text", x  = as.Date("2019-12-30"), y=4.2, label = paste("diff. in means before/after: ", (difference_in_means(pid7_legacy ~ treated, data = full_data %>% filter(as.Date('2019-12-05') < start_date) %>% filter(start_date < as.Date('2020-01-02')))$coefficient[[1]])))

ideo5_graph <- full_data %>%
  mutate(date = as.Date(start_date)) %>%
  group_by(date) %>%
  summarize(ideo5 = mean(ideo5, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = ideo5)) +
  geom_line() +
  geom_vline(xintercept = as.Date("2019-12-18"), color = "red") +
  labs(title = "Political Ideology Before and After 12-18 Impeachment Vote", subtitle = "Higher Score Equals More Conservative")  +
  annotate("text", x  = as.Date("2019-12-30"), y=3.15, label = paste("diff. in means before/after: ", (difference_in_means(ideo5 ~ treated, data = full_data %>% filter(as.Date('2019-12-05') < start_date) %>% filter(start_date < as.Date('2020-01-02')))$coefficient[[1]])))

muslimban_graph <- full_data %>%
  mutate(date = as.Date(start_date)) %>%
  group_by(date) %>%
  summarize(muslimban = mean(muslimban, na.rm = TRUE)) %>%
  ggplot(aes(x = date, y = muslimban)) +
  geom_line() +
  geom_vline(xintercept = as.Date("2019-12-18"), color = "red") +
  labs(title = "View on Muslim Ban Before and After 12-18 Impeachment Vote", subtitle = "Higher Score Equals Less Support for Muslim ban")  +
  annotate("text", x  = as.Date("2019-12-30"), y=1.63, label = paste("diff. in means before/after: ", (difference_in_means(muslimban ~ treated, data = full_data %>% filter(as.Date('2019-12-05') < start_date) %>% filter(start_date < as.Date('2020-01-02')))$coefficient[[1]])))



pres_approval_graph
consider_trump_graph
pid7_legacy_graph
ideo5_graph
muslimban_graph

```


## Question 7: DATA SCIENCE QUESTION

**Extend your work from the previous question to consider other factors, like the possibility of heterogenous treatment effects, confounding variables, or use a more sophisticated approach to statistical inference, like regression discontinuity in time.**

```{r multiple_regression}
#running a standardized multiple regression

std_data <- full_data %>%
  mutate(standardized_pres_approval = scale(pres_approval)) %>%
  mutate(standardized_consider_trump = scale(consider_trump)) %>%
  mutate(standardized_pid7_legacy = scale(pid7_legacy)) %>%
  mutate(standardized_ideo5 = scale(ideo5)) %>%
  mutate(standardized_muslimban = scale(muslimban)) %>%
  mutate(standardized_age = scale(age)) %>%
  mutate(standardized_witnessed_bc_imp = scale(witnessed_bc_imp)) %>%
  mutate(standardized_treated = scale(treated)) %>%
  select(standardized_pres_approval, standardized_consider_trump, standardized_pid7_legacy, standardized_ideo5, standardized_muslimban, standardized_age, standardized_witnessed_bc_imp, standardized_treated)


mr_model <- lm(standardized_pid7_legacy ~ standardized_treated + standardized_pres_approval + standardized_consider_trump + standardized_ideo5 + standardized_muslimban + standardized_age + standardized_witnessed_bc_imp, data = std_data)

plot_summs(mr_model, scale = TRUE, inner_ci_level = .9) +
  labs(title = "Multiple Regression Estimates of Effect on PID7")

```



